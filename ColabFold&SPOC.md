## Important Links

The repo for ColabFold in your local PC is here: https://github.com/YoshitakaMo/localcolabfold

The tutorial for running ColabFold notebook on a HPC over SSH is here: https://www.jameslingford.com/blog/colabfold-hpc-ssh-howto/

The repo for SPOC is here: https://github.com/walterlab-HMS/SPOC

# Run ColabFold

## What is ColabFold and how is it compared to alphafold/2.3.1
ColabFold
- Optimized version of AlphaFold (developed by Mirdita et al.)
- Replaces JackHMMER with MMseqs2 (ultra-fast multiple sequence alignments, MSA).
- Optional smaller databases (e.g., ColabFoldDB) — fits on a laptop/server (~100 GB).
- 5–10x faster inference time.
- Slight tweaks to internal parameters for better multimer handling.
- Slightly lower MSA depth compared to full AlphaFold, but not noticeable for most proteins.
- Supports batch prediction, faster amber relaxation, etc.

AlphaFold 2.3.1
- Original DeepMind release.
- JackHMMER search → very slow but very deep MSAs.
- Requires huge databases like BFD, Uniref90, MGnify (over 2 TB total).
- Very accurate especially for orphan proteins (no homologs).
- Running time: hours per complex if the sequence is long.

## What is the difference between local ColabFold and ColabFold?
ColabFold is a cloud-based version of the AlphaFold model that runs on Google Colab. It provides a convenient way to use AlphaFold without needing to set up the environment locally.

Local ColabFold is essentially the same software as ColabFold, but it's installed and run locally on your system or an HPC cluster. You set it up manually, often in a Python environment with dependencies. This is the one for HPC.

### Create .sh file: ``` nano protein1_protein2.sh ```

### Copy and paste the following script in:

    Example script:
    ```bash
    #!/bin/bash
    #BSUB -q gpu
    #BSUB -R "rusage[mem=20G]"
    #BSUB -J colabfold_models_1_2_3
    #BSUB -gpu "num=1"
    #BSUB -n 1
    #BSUB -W 2:00
    #BSUB -oo MNK1_EIF4E/MNK1_EIF4E_1_2_3.out
    #BSUB -eo MNK1_EIF4E/MNK1_EIF4E_1_2_3.err
    
    # Load the colabfold module
    module load localcolabfold/1.5.5
    LOCALCOLABIMG=/share/pkg/containers/localcolabfold/localcolabfold-1.5.5.sif
    
    # Define input and base output directory
    INPUT="MNK1_EIF4E.fasta"
    BASE_OUT="MNK1_EIF4E"
    
    # Run model 1
    singularity exec --nv $LOCALCOLABIMG colabfold_batch \
         --templates --num-recycle 3 --num-ensemble 1 --num-models 3 $INPUT ${BASE_OUT}
    ```
    - Running 3 models because that's what spoc were training on.
---
# RUN SPOC
## What is SPOC and why we use it?

### Clone the SPOC repository
- To clone the SPOC repository, use the following command:
  ``` bash
  git clone https://github.com/walterlab-HMS/SPOC.git
  ```
- Navigate into the cloned directory: ```cd SPOC```

### Create environment to load necessary dependencies

If you are using conda or miniconda, please refer to original repo. The following is for micromamba

- create the environment:
  ```bash
  micromamba env create -f SPOC/environment.yml
  ```
- activate the environment:
  ``` bash
  micromamba activate spoc_venv
  ```

### Run SPOC 
Here is an example input folder:
```bash
my_afm_predictions_folder/
│-- DONS_HUMAN__MCM3_HUMAN__1374aa.a3m.xz
│-- DONS_HUMAN__MCM3_HUMAN__1374aa_scores_rank_001_alphafold2_multimer_v3_model_1_seed_000.json.xz
│-- DONS_HUMAN__MCM3_HUMAN__1374aa_scores_rank_002_alphafold2_multimer_v3_model_2_seed_000.json.xz
│-- DONS_HUMAN__MCM3_HUMAN__1374aa_scores_rank_003_alphafold2_multimer_v3_model_3_seed_000.json.xz
│-- DONS_HUMAN__MCM3_HUMAN__1374aa_unrelaxed_rank_001_alphafold2_multimer_v3_model_1_seed_000.pdb.xz
│-- DONS_HUMAN__MCM3_HUMAN__1374aa_unrelaxed_rank_002_alphafold2_multimer_v3_model_2_seed_000.pdb.xz
│-- DONS_HUMAN__MCM3_HUMAN__1374aa_unrelaxed_rank_003_alphafold2_multimer_v3_model_3_seed_000.pdb.xz

```
- contains a file with .a3m (which is same for all the model)
- three .json files and three .pdb files generated by colabfold
- Run the prediction by
```bash
python3 run.py my_afm_predictions_folder
```

---
# Run Batch files for colabfold and SPOC
## Colabfold
Example Script for a low number of tasks at once (<20):
```bash
    #!/bin/bash
    # Go to the folder that contains all the folders for fasta file
    cd TEST
    
    # Loop through each folder containing the FASTA file
    for dir in */; do
        # Remove trailing slash to get folder name
        folder=${dir%/}
    
        # Find the fasta file inside the folder
        fasta=$(find "$folder" -maxdepth 1 -name "*.fasta" | head -n 1)
    
        # Skip if no fasta file found
        if [[ -z "$fasta" ]]; then
            echo "No FASTA in $folder, skipping..."
            continue
        fi
    
        # Set job and output file base names based on folder
        base_name=$(basename "$fasta" .fasta)
    
        # Generate a temporary job script
        job_script="${folder}/run_colabfold.bsub"
    
        cat > "$job_script" <<EOF
    #!/bin/bash
    #BSUB -q gpu
    #BSUB -R "rusage[mem=20G]"
    #BSUB -J ${base_name}_models
    #BSUB -gpu "num=1"
    #BSUB -n 1
    #BSUB -W 2:00
    #BSUB -oo ${folder}/${base_name}.out
    #BSUB -eo ${folder}/${base_name}.err
    
    module load localcolabfold/1.5.5
    LOCALCOLABIMG=/share/pkg/containers/localcolabfold/localcolabfold-1.5.5.sif
    
    singularity exec --nv $LOCALCOLABIMG colabfold_batch \
         --templates --num-recycle 3 --num-ensemble 1 --num-models 3 "$fasta" "${folder}"
    
    EOF
    
        # Submit the job
        bsub < "$job_script"
    done

```
Example Script for a large number of tasks, e.g., ~2000
    ```
- The script to run:
    ```bash
    #!/bin/bash
    #BSUB -q gpu
    #BSUB -R "rusage[mem=20G]"
    #BSUB -J colabfold_array[1-XX]  # Replace XX with total number of folders
    #BSUB -gpu "num=1"
    #BSUB -n 1
    #BSUB -W 2:00
    #BSUB -oo TEST/log/job_%J_%I.out
    #BSUB -eo TEST/log/job_%J_%I.err
    
    module load localcolabfold/1.5.5
    
    LOCALCOLABIMG=/share/pkg/containers/localcolabfold/localcolabfold-1.5.5.sif
    
    # Get all folder names into an array
    cd TEST
    folders=($(ls -d */))
    
    # Get the folder corresponding to this array index
    index=$((LSB_JOBINDEX - 1))
    folder="${folders[$index]%/}"
    
    # Find fasta file
    fasta=$(find "$folder" -maxdepth 1 -name "*.fasta" | head -n 1)
    
    # Sanity check
    if [[ -z "$fasta" ]]; then
        echo "No FASTA in $folder, skipping..."
        exit 1
    fi
    
    base_name=$(basename "$fasta" .fasta)
    
    singularity exec --nv $LOCALCOLABIMG colabfold_batch \
         --templates --num-recycle 3 --num-ensemble 1 --num-models 3 "$fasta" "$folder"


    ```
